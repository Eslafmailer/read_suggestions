{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4PE_ORcpLkP"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and pre process"
      ],
      "metadata": {
        "id": "Y8v0MqZSmN74"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vurv1IFZl_Bj"
      },
      "outputs": [],
      "source": [
        "!gdown <ID_data.json>\n",
        "!gdown <ID_cover-vgg.json>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "covers = pd.read_json('/content/cover-vgg.json')\n",
        "covers"
      ],
      "metadata": {
        "id": "KCxcnSXWOo9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU1p0y2-AgZY"
      },
      "outputs": [],
      "source": [
        "full = pd.read_json('/content/data.json')\n",
        "full"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full = full.merge(covers, on='id')"
      ],
      "metadata": {
        "id": "h2sri17POsfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full = full[full['cover'].notna()].copy()"
      ],
      "metadata": {
        "id": "u5vUmmSROt9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAqsELQOmv8m"
      },
      "outputs": [],
      "source": [
        "len(full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtdKf2q7yHD7"
      },
      "outputs": [],
      "source": [
        "def func(acc, val):\n",
        "  acc.update(val)\n",
        "  return acc\n",
        "\n",
        "categories = functools.reduce(func, full['categories'], set())\n",
        "\n",
        "for cat in categories:\n",
        "  full['cat-' + cat] = full['categories'].apply(lambda x: 1 if cat in x else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0lPSSJTBkB1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
        "\n",
        "def func(acc, val):\n",
        "  acc.update(val)\n",
        "  return acc\n",
        "\n",
        "tags = functools.reduce(func, full['tags'], set())\n",
        "\n",
        "for cat in tags:\n",
        "  full['tag-' + cat] = full['tags'].apply(lambda x: 1 if cat in x else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT8o_Qw7Awv7"
      },
      "outputs": [],
      "source": [
        "df = full[full['label'].notna()].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQHmVMGoPWtw"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "2rc-dxSHmRgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF8JcYKrr7E5"
      },
      "outputs": [],
      "source": [
        "df.columns[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcwVuRVlcbUX"
      },
      "outputs": [],
      "source": [
        "regularColumns = ['views', 'pages', 'chapters', 'score', 'votes', 'uploaded', 'cover']\n",
        "catColumns = list(filter(lambda x: x.startswith('cat-'), list(df.columns)))\n",
        "tagColumns = list(filter(lambda x: x.startswith('tag-'), list(df.columns)))\n",
        "X = [*regularColumns, *catColumns, *tagColumns]\n",
        "y = ['label']\n",
        "cat_features = []\n",
        "embedding_features=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FBarjt7veP-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, train_size=0.6, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCZ0S-B9aBfr"
      },
      "outputs": [],
      "source": [
        "! pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from catboost import cv, Pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kr_CSRuIX6K"
      },
      "outputs": [],
      "source": [
        "train_data = Pool(data=train[X],\n",
        "                  label=train[y],\n",
        "                  cat_features=cat_features,\n",
        "                  embedding_features=embedding_features,\n",
        "                 )\n",
        "test_data = Pool(data=test[X],\n",
        "                  label=test[y],\n",
        "                  cat_features=cat_features,\n",
        "                  embedding_features=embedding_features,\n",
        "                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NRekDXca5DG"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'cat_features': cat_features,\n",
        "    'embedding_features': embedding_features,\n",
        "    'eval_metric': 'AUC',\n",
        "    'loss_function': 'Logloss',\n",
        "    'verbose': 100,\n",
        "    'random_seed': 42,\n",
        "    'learning_rate': 0.01,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV49VR74bDbA"
      },
      "outputs": [],
      "source": [
        "cv_data = cv(\n",
        "    params = parameters,\n",
        "    pool = train_data,\n",
        "    fold_count=5,\n",
        "    partition_random_seed=42,\n",
        "    verbose=False,\n",
        "    early_stopping_rounds=200,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKpbbrnxVvAy"
      },
      "outputs": [],
      "source": [
        "n_iters = cv_data[cv_data['test-AUC-mean'] == cv_data['test-AUC-mean'].max()]['iterations'].values[0]\n",
        "n_iters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXHylUNPIj4w"
      },
      "outputs": [],
      "source": [
        "model = CatBoostClassifier(**parameters, iterations=n_iters)\n",
        "model.fit(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze"
      ],
      "metadata": {
        "id": "yekfIRExmW-e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_CGbomibGmh"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "def uplift(df, score, pct):\n",
        "  exited_all = df['label'].sum()\n",
        "  df = df.sort_values(score, ascending=False)\n",
        "  exited_found = df.head(round(len(df) * pct))['label'].sum()\n",
        "\n",
        "  return (exited_found / exited_all) / pct;\n",
        "\n",
        "def auc(df, score):\n",
        "  fpr, tpr, threshold = metrics.roc_curve(df['label'], df[score])\n",
        "  return metrics.auc(fpr, tpr)\n",
        "\n",
        "def print_metrics(df, score):\n",
        "  print(\"log_loss\", metrics.log_loss(df['label'], df[score]))\n",
        "  print(\"uplift\", uplift(df, score, 0.2))\n",
        "  print(\"auc\", auc(df, score))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svz_N6EydPgp"
      },
      "outputs": [],
      "source": [
        "test['label_pred_score'] = model.predict_proba(test[X])[:,1]\n",
        "print_metrics(test, 'label_pred_score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TSTz6BUKsWZ"
      },
      "outputs": [],
      "source": [
        "model.get_feature_importance(prettified=True).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from matplotlib import pyplot\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(test['label'], test['label_pred_score'])\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
        "pyplot.plot(fpr, tpr, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "VZBf5NMy4J46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import sqrt\n",
        "from numpy import argmax\n",
        "\n",
        "gmeans = sqrt(tpr * (1-fpr))\n",
        "ix = argmax(gmeans)\n",
        "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
      ],
      "metadata": {
        "id": "JFux5KLfH6J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "WaoI1KbZmeqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier(**parameters, iterations=n_iters)\n",
        "model.fit(df[X], df[y])"
      ],
      "metadata": {
        "id": "KV-k9anhIEG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = full[full['label'].isna()].copy()\n",
        "len(test_df)"
      ],
      "metadata": {
        "id": "l90H2MKuIhCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['score_pred'] = model.predict_proba(test_df[X])[:,1]\n",
        "test_df['score_pred'].hist()"
      ],
      "metadata": {
        "id": "FP2frKRmImzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.sort_values(by=['score_pred'], ascending=False).head(20)"
      ],
      "metadata": {
        "id": "tSF8AO52X_SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"result.json\", \"w\") as outfile:\n",
        "    json.dump(list(test_df.sort_values(by=['score_pred'], ascending=False).head(20)['name']), outfile)"
      ],
      "metadata": {
        "id": "5gOAWC9oIvLG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}